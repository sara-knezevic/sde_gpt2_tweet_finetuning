{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664cec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import GPT2Model\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435d0d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "tweets = df.tweets.copy()\n",
    "\n",
    "# GPT has a convenient way to handle single column data\n",
    "# using the beginning and end of string tokens\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5416ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Surprise me\n",
       "1        For example, Twitter could very conceivably sc...\n",
       "2        Sort of ya, but whatever might answer the ques...\n",
       "3        This exact problem is why we funded mRelief, t...\n",
       "4                             People actually believe this\n",
       "                               ...                        \n",
       "25547      whoa there, you got a source on that one buddy?\n",
       "25548    Yeah. WOULDNT surprise me she has someone lock...\n",
       "25549    What good is identity? It can make you act irr...\n",
       "25550    you don't have to \"indoctrinate\" people into b...\n",
       "25551    It looks almost neoclassical honestly. I don’t...\n",
       "Name: tweets, Length: 25552, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b8ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=526):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for txt in txt_list:\n",
    "            \n",
    "            encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f2b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GPT2Dataset(tweets, tokenizer, max_length=526)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0d1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d5e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4a0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59173299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = 1\n",
    "        )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7133988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# resizes input token embeddings matrix of the model\n",
    "# so that the model matches the tokenized inputs\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd31fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "seed_val = 47\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2a0e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e3\n",
    "epsilon = 1e-7\n",
    "\n",
    "sample_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d648d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr = learning_rate,\n",
    "                    eps = epsilon\n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                                        optimizer, \n",
    "                                        num_warmup_steps = warmup_steps, \n",
    "                                        num_training_steps = total_steps\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9907bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1,000 of 20,441. Loss: 0.2672589123249054.\n",
      "0:  rewardsIn a community where information about crimes is hard to identify, it can be tricky to tell whether the information has anything to say about it. But to not put it out and open it in the commons is to put it out and open it in the public hands.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2,000 of 20,441. Loss: 0.23278845846652985.\n",
      "0: oonIt's also worth the mention, if you want to spend the week on a man they should do it, don't worry about the problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3,000 of 20,441. Loss: 0.27232059836387634.\n",
      "0: ppyI swear there are not even words words here, just words of ideas with words around their respective objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4,000 of 20,441. Loss: 0.5199285745620728.\n",
      "0: niawho would sell them on some internet connection if she gets it on it?there is no need to prepare on purpose for a massive boom at the bottom, with big money and a cheap pump to get more buys?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5,000 of 20,441. Loss: 0.42935094237327576.\n",
      "0:  ShanI'm a good guess.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6,000 of 20,441. Loss: 0.21982017159461975.\n",
      "0:  ChanI've called it \"the best\" every person has the biggest amount of energy that they want to spend to spend to make it into real-world projects... \"this new\" to happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7,000 of 20,441. Loss: 0.10704772174358368.\n",
      "0:  veteranshe seems very certain, but I absolutely agree with that, that's true. What's it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8,000 of 20,441. Loss: 0.30919840931892395.\n",
      "0:  Bi the a, itI IS and are’I the get,. be that they to this to the this who a as ( a for, be and A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9,000 of 20,441. Loss: 1.495906114578247.\n",
      "0:  \\(If to you, the in is the of is the I the do would that the that the for their that to the, in you are can you people I you can just. about. just it I really\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10,000 of 20,441. Loss: 0.31290221214294434.\n",
      "0: pringI'm not the good for a get I don't do are \" He're an get use some are so you believe your'm do you're get is.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11,000 of 20,441. Loss: 0.25677335262298584.\n",
      "0: �\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12,000 of 20,441. Loss: 0.3957837224006653.\n",
      "0:  IndustriesFor \"in the point are a lot about a point as a very full-as!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13,000 of 20,441. Loss: 0.19431623816490173.\n",
      "0:  skI have much right this, but that has a \"bh. Is that, but to be an reason you have wrong because I'm wrong.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14,000 of 20,441. Loss: 0.11335599422454834.\n",
      "0: DurationT IS E ALL MION THE BE THE SOC ALL THE BOSE TO ARE THNAIALES IN THE NILL TO TO THE THENILY THEONGFTTH NO TH OF THE THIND ON TOION OF THE THTH OUT NO THE TO THE THREAD OUT THY ARE OF MORE OF THE PLINKEN YOU IN A BE THEN OF BE ALL ARE OF FFTS INY THE THREADREADY THED THONG ALL MOREURE OF THE ANIND THE ATHFTURE PEOPLE SHOULD SHOULD PEOPLE ALL THFTE THEREAD THEES THE OF TH THE YOUR YOUR THONG TOESILIAL OUT WITH SHOULD BEYENIND SHOULD ALLYINDIONENTY IN PEOPLEING TO TO MREADFT THFT ARE PEOPLE NO IN NOION ALL IN OF SHOULDURE ALL OF THIS PEOPLE ON THE THAT TO PEOPLE THFTIALEN THE THE THE THE A ON BEING PEOPLE TO SHOULD SHOULD BE IS THINKREADREAD OUT THS THE AONG ALL TO ALL OF THE THIND SHOULD TO SHOULD BFT TH SHOULD ON ON YOUR THE THINDIND THE BY THELF ALL THOSE THFT OUT TO THE THE MORE OF AREAD TOURE THE HY TO ON THION OF THE ON OF NIND THENT ALL OF E OF ARE THURFT TO TH IN ON TO IS THE YOU ON THE SHOULD TH TH OF IS ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15,000 of 20,441. Loss: 0.19041919708251953.\n",
      "0: FixedI'd not a man was trying to have with the face that, a fucking way like if it was possible to the story.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16,000 of 20,441. Loss: 0.2995605170726776.\n",
      "0:  CreationWgt; He's even be very similar and I'm not genuinely even hard to be been not seen that being \"hbrito\" it. But they've said when you were wrong to be like more interesting and really hard to get a lot and the whole. They'll expect to be available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17,000 of 20,441. Loss: 0.0522315688431263.\n",
      "0: athIt would not be a joke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18,000 of 20,441. Loss: 0.6455888152122498.\n",
      "0: imatelyyou want someone to keep a lot about a lot of sex by the only reason?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19,000 of 20,441. Loss: 0.20341244339942932.\n",
      "0: 6I have an open by people in particular. that's not completely even how it's completely the reason about people were the best thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20,000 of 20,441. Loss: 0.284874826669693.\n",
      "0: GenerED REMOUGH IMPITATIVE TECHKOVED ONNOVATION TAY OF ACCIPIPOTAL IS ABOUT IT TO FRES THALKS TORTIONS TO NEVER BE A CAIN HOW TO BE IT WAS IMPORT IN THIS REK\n",
      "\n",
      "Running Testing...\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1,000 of 20,441. Loss: 0.11801905184984207.\n",
      "0:  IPvAFAIK IS EGO TO BE, AFAIK in that the world needs to be near the future. It is bad to become more than the world would be a startup by being used to them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2,000 of 20,441. Loss: 0.17886687815189362.\n",
      "0:  BecThis is how many people aren't good, but a thing I don't realize the most rich people want for it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3,000 of 20,441. Loss: 0.35760870575904846.\n",
      "0:  SilvaI'd not have the first few times to have been given as a little different one. It's a 5% 2: if it's all the one of what will make the average less-5 years.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4,000 of 20,441. Loss: 0.45202451944351196.\n",
      "0: abi... I have to see what happens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5,000 of 20,441. Loss: 0.43238189816474915.\n",
      "0:  lmao. my long as a good example, my life is worth. I'm very hard enough. I'd pay you for myself\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6,000 of 20,441. Loss: 0.14558008313179016.\n",
      "0: obyYeah I do not make them from what he'd or do that. what it shouldn't or for me to find at being used:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7,000 of 20,441. Loss: 0.2723815143108368.\n",
      "0:  marketedIt's just not a strong goal on twitter and twitter is a big.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8,000 of 20,441. Loss: 0.23808027803897858.\n",
      "0: cluded\"the guy has since been talking about me (which made me* my last time with it\". I would have to remember: I'd read this one couple times:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9,000 of 20,441. Loss: 0.04897104576230049.\n",
      "0:  simplerI'm not sure if I was going to use a game from PoW over by PoS. All the crypto isn't the PoS-of-of-based case, where PoS gets PoS isn't great, and to be the best hold that stuff. This creates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10,000 of 20,441. Loss: 0.12445640563964844.\n",
      "0:  singerjust get on this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11,000 of 20,441. Loss: 0.08633144944906235.\n",
      "0:  stretchIn general, this is why it is really a thing to do the fact that it's all not what I do, more people than it, but. All of them will say as well as I'm gonna think it's bad to see what a bunch of you understand what they do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12,000 of 20,441. Loss: 0.2505572736263275.\n",
      "0:  schemeYou can just be bad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13,000 of 20,441. Loss: 0.06291641294956207.\n",
      "0: patchThe people who make a good blue bar in the Bay Area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14,000 of 20,441. Loss: 0.12999327480793.\n",
      "0:  liftingBirliant this will be a bit different.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15,000 of 20,441. Loss: 0.5291248559951782.\n",
      "0:  verifyIf you can't get me, and it's just a good problem where you mean \"I get your views\" etc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16,000 of 20,441. Loss: 0.30834126472473145.\n",
      "0: onerI'm not on the bottom of these cultural norms, I think it's not a problem for other who are both the state. The state/the government/authoritarian, \"un-lethal\" is a small result of the real-waking (or/social economy) a \"social\" (which it never will be effectively to measure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17,000 of 20,441. Loss: 0.5315341353416443.\n",
      "0:  wonderfulHe really does all the time-day, especially for the reason to have not been written by The West with the Wokeism and the West\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18,000 of 20,441. Loss: 0.0542093850672245.\n",
      "0:  cur\"THE MARILOLI HATE TO THE USILVIRIDITY TO THE A COLER OF THE A LOT OF IT THEMS OF THE FONES, BUT TO BEINGING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19,000 of 20,441. Loss: 0.33549731969833374.\n",
      "0:  administratorI also said that the best and most dangerous stuff on my left wing are people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20,000 of 20,441. Loss: 0.0999692976474762.\n",
      "0: BMI also don’t think this as a normal problem.But I can also guess if everyone else doesn’t understand how to play around the rest. That would be very easy to decide whether.\n",
      "\n",
      "Running Testing...\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1,000 of 20,441. Loss: 0.10445742309093475.\n",
      "0:  NateIt's a sign because the data processing algorithm doesn't work for Bitcoin, but the algorithm that might be interesting, and they probably want to sell in a new name instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2,000 of 20,441. Loss: 0.35214027762413025.\n",
      "0:  omittedIf you don't believe that it's already the way you're doing this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3,000 of 20,441. Loss: 0.4850826561450958.\n",
      "0:  HamiltonYeah, but not, I don’t. You’re a bad skil tbh but I only have it but to say that again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4,000 of 20,441. Loss: 0.08823464065790176.\n",
      "0: EverythingI think the main part I'm gonna be doing is to be able to take out and more easily with one and another startup in the past couple months.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5,000 of 20,441. Loss: 0.0531083419919014.\n",
      "0:  BeingIf there were people whose lives then the lives are also living in the West. There will have been a living in a land that is safe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6,000 of 20,441. Loss: 0.2003236711025238.\n",
      "0:  HammerI do think we're not gonna build our own children. You want to be a middle class. You can tell him when you want two jobs. He doesn't matter, his parents don't really want to say. He doesn’t know why they hate our kids.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7,000 of 20,441. Loss: 0.41771259903907776.\n",
      "0:  nationallyThe only way to make an existence of the world it can do is that we do, as a result, we don't have in the world, it's like that. Or do you have to have to think of that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8,000 of 20,441. Loss: 0.35600918531417847.\n",
      "0:  �There are plenty of things you can look about who know about them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9,000 of 20,441. Loss: 0.4626334309577942.\n",
      "0: ergPeople think it's good that they may take more from the future, and the people who think that way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10,000 of 20,441. Loss: 0.14925092458724976.\n",
      "0:  PolicyI read my own book on \"I’m not gonna go straight by any third person\" - \"I am a bad person?\" Well, that’s not good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11,000 of 20,441. Loss: 0.12202730029821396.\n",
      "0: BodySounds like a good idea. There's no content. EACH.E.g.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12,000 of 20,441. Loss: 0.41188961267471313.\n",
      "0:  fatallyYou can help much if you're a \"trained company, but if that’s a good thing, it must be a good move.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13,000 of 20,441. Loss: 0.17764727771282196.\n",
      "0: commentin most cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14,000 of 20,441. Loss: 0.5035473704338074.\n",
      "0: scope\"The idea is that you don't share your account over the world\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15,000 of 20,441. Loss: 0.5134050250053406.\n",
      "0: 11Why would it be? I can be careful of what the first step you'd have on. The first rule in the next year: the first time you don't be a good leader, the second later, will still be the best and start these.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16,000 of 20,441. Loss: 0.3272613286972046.\n",
      "0:  placesThe one of your tweets are the first ones you have ever studied. I'm not sure why I've been in a different place. She had the first time. She was a single girl of mine too few minutes. The best friends were me, but mostly good and beautiful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17,000 of 20,441. Loss: 0.08804266899824142.\n",
      "0: CONYes I'll dumpED TO A FINALLY FOCUTIONS AT THE CONSTANT. TO RINTURE, IF YOU WANT TO NOT TENICT TO FAKE ANYTHING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18,000 of 20,441. Loss: 0.09331559389829636.\n",
      "0:  standardThe US has not had any interest in this tax-carrying it's \"am I going to buy bitcoin again and pay my doodily\" and it makes everyone want to pay for it. I think you can't be patient. I hope that's the situation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19,000 of 20,441. Loss: 0.22895853221416473.\n",
      "0: awksIt's possible for me to think. He's a better friend than a friend and an oldER. So even if he's just as lucky as he can get out!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20,000 of 20,441. Loss: 0.2517152428627014.\n",
      "0: otherapyI don't think I have to be able to escape. I think the most authority in the whole world isn't worth it.\n",
      "\n",
      "Running Testing...\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1,000 of 20,441. Loss: 0.20223179459571838.\n",
      "0: ighedIt's also not really like this but I remember hearing it, so definitely I know it. All I know is that the answer is as old as I'm aware of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2,000 of 20,441. Loss: 0.3506355881690979.\n",
      "0:  ArmedI'm sure he'll find the opiate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3,000 of 20,441. Loss: 0.04248211905360222.\n",
      "0: AdditionalI think it does for me to be a straight white male m. She's also a racist. Also, I might have m8 to make an entire identity. I don't even consider hermit to say that to be the end of your political spectrum.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4,000 of 20,441. Loss: 0.10224205255508423.\n",
      "0:  JoanI'd be pleased to say that in the mirror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5,000 of 20,441. Loss: 0.09165028482675552.\n",
      "0: regonno the only way i read it is what I want and what it makes, the other half I've worked hard and got a whole whole really really really really really really really really really really really really really really really really hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6,000 of 20,441. Loss: 0.09084869921207428.\n",
      "0:  biWhat? What do your worst tweets?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7,000 of 20,441. Loss: 0.6148510575294495.\n",
      "0: 205There's a real truth and there's nothing in play there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8,000 of 20,441. Loss: 0.2329113483428955.\n",
      "0: FranceMaybe Elon would start a DAO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9,000 of 20,441. Loss: 0.41456159949302673.\n",
      "0:  abbreI had onlyfans on Twitter but I actually didn't look up until the post. Now this is a failure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10,000 of 20,441. Loss: 0.13136246800422668.\n",
      "0: AmericanThere did not have access, including the NYT and was widely read by tech insiders. Look for your NYT and the press to find you to read it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11,000 of 20,441. Loss: 0.5267097353935242.\n",
      "0:  Solomon\"We had to clarify the correction to this exchange for e-link, which we had to agree on.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12,000 of 20,441. Loss: 0.31230175495147705.\n",
      "0:  AppsIt was all very nice to have a conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13,000 of 20,441. Loss: 0.06022137776017189.\n",
      "0:  cumI disagree the point is that it's not that the right people hold it against me after the fact that I don't like him (stfu) and I'll also be wrong.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14,000 of 20,441. Loss: 0.13118980824947357.\n",
      "0:  Conservthey all use - they never use the word to quote the question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15,000 of 20,441. Loss: 0.1627255380153656.\n",
      "0:  financingno don't worry. I said that was the first time I moved, the second shot. but if you were being there, you should get the explanation and then know your explanation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16,000 of 20,441. Loss: 0.10917560756206512.\n",
      "0:  HankThis is going on forever but honestly, I'm not going to. I don't think I should use DOGE against DOGEBULLch. That's a great way to pump out now. If anything on the books, they should have had to price a certain price for a given.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17,000 of 20,441. Loss: 0.4675069749355316.\n",
      "0: ianceWe must all stop people from having an ancient ancient... from ancient human nature, all of which was meant by some of those who lived in ancient empires, would beel slave in some primitive kind of broken ways?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18,000 of 20,441. Loss: 0.04592578113079071.\n",
      "0:  liabilitiesthe first real question is *this* sexual orientation. if you are more sexual, your sexual orientation will be legal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19,000 of 20,441. Loss: 0.03067287988960743.\n",
      "0: ustersI'm not here to play this game for the people I don't live in, and I don't think we have bad expectations for that kind of thing, the lack of \"good\" ideas are good for the long-term.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20,000 of 20,441. Loss: 0.10996535420417786.\n",
      "0:  EAAnd as you can tell, there’s a good reason why the man isn’t able to find access for women. This isn’t something that happens. Just don’t make it explicit that your beliefs are impossible.\n",
      "\n",
      "Running Testing...\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1,000 of 20,441. Loss: 0.343625545501709.\n",
      "0:  wandIs that a real world thing? Imagineagine something different?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2,000 of 20,441. Loss: 0.10634515434503555.\n",
      "0: alshYeah I went from there\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3,000 of 20,441. Loss: 0.06571092456579208.\n",
      "0:  Forgotten“No duck ass”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4,000 of 20,441. Loss: 0.0752381682395935.\n",
      "0: mic&gt; coinbase became widely available in 10 years.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5,000 of 20,441. Loss: 0.11498396843671799.\n",
      "0:  yen(and as we know, people actually are literally asking for themselves to do it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6,000 of 20,441. Loss: 0.10174445062875748.\n",
      "0: elsenMy Twitter isn’t really enough\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7,000 of 20,441. Loss: 0.18184253573417664.\n",
      "0:  SergeantWhat’s the best “villa” We are living in the longs. The actual attempt to convince someone that the “ remembered bad is the enemy” of any old man and our supposed—is. And we’ve lost a wealth concentration of a war on our own...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8,000 of 20,441. Loss: 0.05631910637021065.\n",
      "0:  StillI was joking. I'd have to guess tbh. One more times before that, and since a few more times... still worth reading all the time, I've been chatting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9,000 of 20,441. Loss: 0.2148927003145218.\n",
      "0: 377The average age study in this study is basically low.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10,000 of 20,441. Loss: 0.4773012399673462.\n",
      "0:  epidemic\"It's true for insurance companies in the next disease\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11,000 of 20,441. Loss: 0.08220940083265305.\n",
      "0:  rememI don't even know who to give them probability, but I'm not sure what To*. I bet on the future of the 2020s once it's a baby.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12,000 of 20,441. Loss: 0.04946780577301979.\n",
      "0: ressingThe other problem with BTC is that the government bond itself has 0 lead, BITCOIN rate, technicality etc. And in current BTC I mean 50%. The real estate' dating is pretty much of a stock. I think people will have to give the benefit of the country.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13,000 of 20,441. Loss: 0.2679298222064972.\n",
      "0:  ChileThere would be a great opportunity if people had seen this one:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14,000 of 20,441. Loss: 0.041833359748125076.\n",
      "0:  verseI wonder if that's a big problem for the public spaces.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15,000 of 20,441. Loss: 0.12855638563632965.\n",
      "0:  15yes, it was, the worst.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16,000 of 20,441. Loss: 0.19163575768470764.\n",
      "0: VERTAnd you want something to say, I think it’s pretty well structured, and frankly, as you get to feel, it’s probably a good way to look obese for himself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17,000 of 20,441. Loss: 0.08456148207187653.\n",
      "0:  DigitalFor women, the best “gary” in the world is to put men in a detransition or a w/o full-time brookol. It’s never even true for people who don’t make everything work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18,000 of 20,441. Loss: 0.04118768870830536.\n",
      "0:  revisionyes, that is how u feel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19,000 of 20,441. Loss: 0.24455484747886658.\n",
      "0: umbledoreIt's like you meant. There's a very particular set of \" moves\" in the sense that there will be no real push for a reactionary narrative from behind this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20,000 of 20,441. Loss: 0.10838542133569717.\n",
      "0:  PDFyes, i know you're still on the internet.\n",
      "\n",
      "Running Testing...\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            print('Batch {:>5,} of {:>5,}. Loss: {:>5,}.'.format(step, len(train_dataloader), batch_loss))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 280,\n",
    "                                    top_p=0.99, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        \n",
    "    # Testing\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Testing...\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids,\n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Testing Loss': avg_val_loss\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3feb1ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Testing Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Testing Loss\n",
       "epoch                             \n",
       "1               0.31          0.30\n",
       "2               0.28          0.27\n",
       "3               0.24          0.27\n",
       "4               0.20          0.27\n",
       "5               0.15          0.28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ead2d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style='darkgrid')\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Testing Loss'], 'g-o', label=\"Testing\")\n",
    "\n",
    "# plot labels\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8225d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPT-2 model has 148 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "transformer.wte.weight                                  (50259, 768)\n",
      "transformer.wpe.weight                                   (1024, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "transformer.h.0.ln_1.weight                                   (768,)\n",
      "transformer.h.0.ln_1.bias                                     (768,)\n",
      "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
      "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
      "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
      "transformer.h.0.attn.c_proj.bias                              (768,)\n",
      "transformer.h.0.ln_2.weight                                   (768,)\n",
      "transformer.h.0.ln_2.bias                                     (768,)\n",
      "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
      "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
      "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
      "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "transformer.ln_f.weight                                       (768,)\n",
      "transformer.ln_f.bias                                         (768,)\n"
     ]
    }
   ],
   "source": [
    "# get all of the model's parameters\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:2]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[2:14]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5e5db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.json',\n",
       " './model_save/merges.txt',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = './model_save/'\n",
    "\n",
    "# create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86afa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('./model_save/', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c65617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained('./model_save/', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('./model_save/')\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e871eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c430617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257]], device='cuda:0')\n",
      "1: This is why I'm not pro death. I don't support death, I'm not saying that life has should be killed.I don't support death if it does. I'm alone, nobody would want to die.\n",
      "\n",
      "\n",
      "2: I think this is actually an interesting situation. It's hard to find out precisely the optimal solution.\n",
      "\n",
      "\n",
      "3: I've had no money to do this for a while now and I've been a latecomer since then I went back to look great.\n",
      "\n",
      "\n",
      "4: I think that a lot of people would be better off seeing this than being honest with me. I think  is actually correct but also, importantly I believe you’re mistaken. I’re saying you’re wrong because you’re mistaken. Do you believe me?\n",
      "\n",
      "\n",
      "5: Yes, the real reason values are good. But the real question is that \"you can dollar-cost averaging into Bitcoin without running out of Ethereum!\" coins that people will get better and more of that \"you have a few.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"<|startoftext|>\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "\n",
    "print(generated)\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "                                generated,\n",
    "                                do_sample=True,   \n",
    "                                top_k=15, \n",
    "                                max_length = 280,\n",
    "                                top_p=0.99, \n",
    "                                num_return_sequences=5\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\\n\\n\".format(i + 1, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932e15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
